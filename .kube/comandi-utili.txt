$env:KUBECONFIG = "C:\Users\Carlo\Desktop\Tesi\.kube\config.new"

helm install custom-pod-autoscaler-operator https://github.com/jthomperoo/custom-pod-autoscaler-operator/releases/download/v1.4.2/custom-pod-autoscaler-operator-v1.4.2.tgz

helm install opencost --repo https://opencost.github.io/opencost-helm-chart opencost --namespace default

kubectl apply -f https://github.com/jthomperoo/custom-pod-autoscaler-operator/releases/download/v1.1.0/cluster.yaml


helm install my-pyrra rlex/pyrra --version 0.14.2
NAME: my-pyrra
LAST DEPLOYED: Mon Mar 10 09:14:52 2025
NAMESPACE: default
STATUS: deployed
REVISION: 1
NOTES:
1. Get the application URL by running these commands:
  export POD_NAME=$(kubectl get pods --namespace default -l "app.kubernetes.io/name=pyrra,app.kubernetes.io/instance=my-pyrra" -o jsonpath="{.items[0].metadata.name}")
  export CONTAINER_PORT=$(kubectl get pod --namespace default $POD_NAME -o jsonpath="{.spec.containers[0].ports[0].containerPort}")
  echo "Visit http://127.0.0.1:8080 to use your application"
  kubectl --namespace default port-forward $POD_NAME 8080:$CONTAINER_PORT
  
  
helm install prometheus --repo https://prometheus-community.github.io/helm-charts prometheus --namespace default --set prometheus-pushgateway.enabled=false --set alertmanager.enabled=false -f https://raw.githubusercontent.com/opencost/opencost/develop/kubernetes/prometheus/extraScrapeConfigs.yaml

The Prometheus server can be accessed via port 80 on the following DNS name from within your cluster:
prometheus-server.default.svc.cluster.local

Get the Prometheus server URL by running these commands in the same shell:
  export POD_NAME=$(kubectl get pods --namespace default -l "app.kubernetes.io/name=prometheus,app.kubernetes.io/instance=prometheus" -o jsonpath="{.items[0].metadata.name}")
  kubectl --namespace default port-forward $POD_NAME 9090
  
helm install opencost --repo https://opencost.github.io/opencost-helm-chart opencost --namespace default -f helm-values.yaml

helm upgrade prometheus --repo https://prometheus-community.github.io/helm-charts prometheus --namespace default --set prometheus-pushgateway.enabled=false --set alertmanager.enabled=false -f custom-extraScrapeConfigs.yaml

helm upgrade prometheus --repo https://prometheus-community.github.io/helm-charts prometheus --namespace default --set prometheus-pushgateway.enabled=false --set alertmanager.enabled=false --set-file prometheus.additionalScrapeConfigs=custom-extraScrapeConfigs.yaml

docker build -t test-target:latest .

docker tag test-target:latest carlito9675/test-target:latest

docker push carlito9675/test-target:latest


kubectl delete -f https://github.com/jthomperoo/custom-pod-autoscaler-operator/releases/download/v1.1.0/cluster.yaml

docker build -t app-target:latest .
docker tag app-target:latest carlito9675/app-target:latest
docker push carlito9675/app-target:latest

kubectl port-forward svc/app-service 8090:90 -n default
kubectl port-forward svc/prometheus-server 9090:80 -n default

kubectl apply -f pyrra-latency-slo.yaml

kubectl exec -it python-custom-autoscaler -n default -- tail -f /shared/metric-gather.log

kubectl exec -it python-custom-autoscaler -n default -- tail -f /shared/metric-evaluate.log

kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

kubectl apply -f https://k8s.io/examples/application/php-apache.yaml

kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10

kubectl get hpa

# Run this in a separate terminal
# so that the load generation continues and you can carry on with the rest of the steps
kubectl run -i --tty load-generator --rm --image=busybox:1.28 --restart=Never -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://php-apache; done"

kubectl get hpa php-apache --watch

helm repo add grafana https://grafana.github.io/helm-charts
helm repo update

helm install grafana grafana/grafana -n default -f grafana.yaml --set service.type=ClusterIP --set adminPassword='admin'

helm upgrade grafana grafana/grafana --namespace default --set service.type=ClusterIP

kubectl port-forward svc/grafana 3000:3000 -n default


kubectl cost --service-port 9003 --service-name opencost --kubecost-namespace default --allocation-path /allocation/compute   namespace --historical --window 5d  --show-cpu --show-memory --show-pv --show-efficiency=false

docker build -t carlito9675/locust:latest .
docker push carlito9675/locust:latest

kubectl apply -f locust-deployment.yaml
kubectl apply -f locust-service.yaml

helm upgrade prometheus --repo https://prometheus-community.github.io/helm-charts prometheus --namespace default -f custom-extraScrapeConfigs.yaml

kubectl exec -it locust-deployment-848c5f84dd-vd8jh -- locust -f locust_test.py --host http://app-service:90 --headless -u 100 -r 10 --csv=/tmp/locust-stats --run-time 20m

helm repo add deliveryhero https://charts.deliveryhero.io/
helm repo update

helm install prometheus-locust-exporter deliveryhero/prometheus-locust-exporter --namespace default --set config.locust_uri=http://locust-service.default.svc.cluster.local:8089

kubectl autoscale deployment app-target-hpa --cpu-percent=50 --min=1 --max=10

kubectl get hpa app-target-hpa --watch

kubectl autoscale deployment app-target --cpu-percent=50 --min=1 --max=10

kubectl get hpa app-target --watch



kubectl logs log-reader-76ff9b6ddf-j4kc8 -n default --follow
kubectl port-forward svc/grafana 3001:80 -n default
kubectl port-forward -n default svc/prometheus-server 9090:80
kubectl port-forward service/locust-service 8089:8089